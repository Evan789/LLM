📌 场景：电影评论情感分类
使用 BERT 对文本进行分类的简单场景

目标：判断一句电影评论是 积极 (positive) 还是 消极 (negative)。
我们使用 Hugging Face 的 transformers 库来调用预训练的 BERT 模型。

# 安装依赖（如果未安装）
# pip install torch transformers

from transformers import BertTokenizer, BertForSequenceClassification
from transformers import pipeline

# 1. 加载预训练的BERT模型 (情感分类)
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
classifier = pipeline("sentiment-analysis", model=model_name)

# 2. 输入一些电影评论
reviews = [
    "这部电影真的很棒，我非常喜欢！",
    "剧情太差了，浪费了两个小时。",
    "演员的表演一般般，但画面很美。",
]

# 3. 执行分类
results = classifier(reviews)

# 4. 打印结果
for review, result in zip(reviews, results):
    print(f"评论: {review}")
    print(f"预测结果: {result['label']}，置信度: {result['score']:.2f}")
    print("-" * 30)

-------------------------------------------------------------------------
运行结果：

评论: 这部电影真的很棒，我非常喜欢！
预测结果: 5 stars，置信度: 0.89
------------------------------
评论: 剧情太差了，浪费了两个小时。
预测结果: 1 star，置信度: 0.92
------------------------------
评论: 演员的表演一般般，但画面很美。
预测结果: 3 stars，置信度: 0.67
------------------------------

在上面的例子里，label 和 score 是 BERT 分类模型输出的结果，它们的来源是这样的：

🔹 1. BERT 模型输出什么？

BERT 在做分类时，输入的文本会经过：

Tokenizer → 把文本拆成词片段（tokens），转成向量。

BERT Encoder → 输出每个 token 的上下文表示。

[CLS] 向量 → 取句子开头的特殊 token [CLS] 的向量，作为整句话的语义表示。

分类层 (Linear + Softmax) → 把 [CLS] 向量输入到一个线性层，最后用 softmax 得到各类别的概率分布。

🔹 2. label 的来源

模型在训练时用的数据集是带标签的，比如情感分类的数据集里：

1 star → 极度负面

2 stars → 负面

3 stars → 中性

4 stars → 正面

5 stars → 极度正面

训练完之后，模型的输出类别就固定为这些标签。
所以 label 就是 softmax 概率最高的那个类别名称。

例如：

[1 star, 2 stars, 3 stars, 4 stars, 5 stars]

🔹 3. score 的来源

score 就是 softmax 输出的 概率值（范围 0~1 之间）。

表示模型对这个预测结果的置信度。

举个例子：
输入 "这部电影真的很棒，我非常喜欢！"

Softmax 输出可能是：

1 star: 0.01
2 stars: 0.02
3 stars: 0.03
4 stars: 0.05
5 stars: 0.89


那么：

label = "5 stars"

score = 0.89

✅ 总结：

label → 来自于训练好的分类任务标签（例如 1~5 星）。

score → 来自于 softmax 输出的概率，表示置信度。
