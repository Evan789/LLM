📌 场景：电影评论情感分类
使用 BERT 对文本进行分类的简单场景

目标：判断一句电影评论是 积极 (positive) 还是 消极 (negative)。
我们使用 Hugging Face 的 transformers 库来调用预训练的 BERT 模型。

# 安装依赖（如果未安装）
# pip install torch transformers

from transformers import BertTokenizer, BertForSequenceClassification
from transformers import pipeline

# 1. 加载预训练的BERT模型 (情感分类)
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
classifier = pipeline("sentiment-analysis", model=model_name)

# 2. 输入一些电影评论
reviews = [
    "这部电影真的很棒，我非常喜欢！",
    "剧情太差了，浪费了两个小时。",
    "演员的表演一般般，但画面很美。",
]

# 3. 执行分类
results = classifier(reviews)

# 4. 打印结果
for review, result in zip(reviews, results):
    print(f"评论: {review}")
    print(f"预测结果: {result['label']}，置信度: {result['score']:.2f}")
    print("-" * 30)

-------------------------------------------------------------------------
运行结果：

评论: 这部电影真的很棒，我非常喜欢！
预测结果: 5 stars，置信度: 0.89
------------------------------
评论: 剧情太差了，浪费了两个小时。
预测结果: 1 star，置信度: 0.92
------------------------------
评论: 演员的表演一般般，但画面很美。
预测结果: 3 stars，置信度: 0.67
------------------------------------------------------------------------------

1   从 Hugging Face transformers 库中导入两个主要工具：
    BertTokenizer：BERT 的分词器，可把文本转成模型能理解的 token（这里没直接用，因为 pipeline 已经帮我们封装好了）。
    BertForSequenceClassification：带有分类头的 BERT 模型，可以做文本分类任务。
    pipeline：官方封装好的高级接口，一行代码就能完成推理，非常适合入门和快速实验。
    
    label → 来自于训练好的分类任务标签（例如 1~5 星）。
    
    score → 来自于 softmax 输出的概率，表示置信度。

2   这里做了两件事：
    选择模型：
    使用了 nlptown/bert-base-multilingual-uncased-sentiment，这是一个在多语言影评数据上训练过的 BERT 模型，可以输出情绪星级（1 星到 5 星）。
    构建 pipeline：
    pipeline("sentiment-analysis", model=model_name) 创建了情感分析器。之后只需要输入文本字符串，它就会自动：
    分词
    向量化
    喂给 BERT 模型
    输出分类结果（标签+置信度）。

3   输入我们的 reviews 列表给 classifier，输出结果列表 results

4   遍历每条评论对应的预测结果，逐条打印：
    原始评论文本。
    模型的预测标签（星级）。
    模型的预测置信度，保留两位小数。
    分隔线（"-"*30）。
-----------------------------------------------------------------------

📌 总结
这段代码流程：

加载模型 → 使用预训练多语言 BERT 做情感分析。
准备数据 → 输入几条示例评论。
执行预测 → 调用 pipeline 自动完成特征提取+推理。
输出结果 → 打印预测的星级和置信度。
✅ 这就是一个 BERT 多语言影评情感分类实验。
