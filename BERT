ğŸ“Œ åœºæ™¯ï¼šç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»
ä½¿ç”¨ BERT å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»çš„ç®€å•åœºæ™¯

ç›®æ ‡ï¼šåˆ¤æ–­ä¸€å¥ç”µå½±è¯„è®ºæ˜¯ ç§¯æ (positive) è¿˜æ˜¯ æ¶ˆæ (negative)ã€‚
æˆ‘ä»¬ä½¿ç”¨ Hugging Face çš„ transformers åº“æ¥è°ƒç”¨é¢„è®­ç»ƒçš„ BERT æ¨¡å‹ã€‚

# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
# pip install torch transformers

from transformers import BertTokenizer, BertForSequenceClassification
from transformers import pipeline

# 1. åŠ è½½é¢„è®­ç»ƒçš„BERTæ¨¡å‹ (æƒ…æ„Ÿåˆ†ç±»)
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
classifier = pipeline("sentiment-analysis", model=model_name)

# 2. è¾“å…¥ä¸€äº›ç”µå½±è¯„è®º
reviews = [
    "è¿™éƒ¨ç”µå½±çœŸçš„å¾ˆæ£’ï¼Œæˆ‘éå¸¸å–œæ¬¢ï¼",
    "å‰§æƒ…å¤ªå·®äº†ï¼Œæµªè´¹äº†ä¸¤ä¸ªå°æ—¶ã€‚",
    "æ¼”å‘˜çš„è¡¨æ¼”ä¸€èˆ¬èˆ¬ï¼Œä½†ç”»é¢å¾ˆç¾ã€‚",
]

# 3. æ‰§è¡Œåˆ†ç±»
results = classifier(reviews)

# 4. æ‰“å°ç»“æœ
for review, result in zip(reviews, results):
    print(f"è¯„è®º: {review}")
    print(f"é¢„æµ‹ç»“æœ: {result['label']}ï¼Œç½®ä¿¡åº¦: {result['score']:.2f}")
    print("-" * 30)
