RAG çš„ä»£ç å®ç°æµç¨‹

1. æ•°æ®å‡†å¤‡ & å‘é‡åŒ–

æ”¶é›†ä½ çš„æ–‡æ¡£ï¼ˆPDFã€ç½‘é¡µã€æ•°æ®åº“è®°å½•ç­‰ï¼‰ã€‚

ä½¿ç”¨ embedding æ¨¡å‹ï¼ˆå¦‚ OpenAI Embeddingsã€Sentence-BERTï¼‰æŠŠæ–‡æ¡£åˆ‡åˆ†æˆç‰‡æ®µï¼Œå¹¶è½¬åŒ–ä¸ºå‘é‡ã€‚

æŠŠè¿™äº›å‘é‡å­˜å…¥ä¸€ä¸ª å‘é‡æ•°æ®åº“ï¼ˆå¦‚ Pineconeã€FAISSã€Weaviateï¼‰ã€‚
------
from openai import OpenAI
import faiss
import numpy as np

client = OpenAI()

# ç¤ºä¾‹æ–‡æ¡£
docs = ["å®é©¬å‘å¸ƒäº†æœ€æ–° recall...", "RAG æ˜¯ä¸€ç§å¢å¼ºç”Ÿæˆæ¨¡å‹çš„æ¶æ„..."]

# è·å–å‘é‡
embeddings = [client.embeddings.create(model="text-embedding-ada-002", input=doc).data[0].embedding for doc in docs]

# å­˜å…¥å‘é‡åº“ (FAISS)
dim = len(embeddings[0])
index = faiss.IndexFlatL2(dim)
index.add(np.array(embeddings).astype('float32'))
------

2. ç”¨æˆ·è¾“å…¥æŸ¥è¯¢

ç”¨æˆ·æå‡ºé—®é¢˜ï¼ŒæŠŠé—®é¢˜è½¬åŒ–ä¸ºå‘é‡ embeddingã€‚

åœ¨å‘é‡åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚

------
query = "å®é©¬ recall ä¸€èˆ¬æ¶‰åŠå“ªäº›æ›´æ–°ï¼Ÿ"
query_vec = client.embeddings.create(model="text-embedding-ada-002", input=query).data[0].embedding

# æ£€ç´¢å‰2ä¸ªæœ€ç›¸ä¼¼æ–‡æ¡£
D, I = index.search(np.array([query_vec]).astype('float32'), k=2)
retrieved_docs = [docs[i] for i in I[0]]
------


3. ç»„åˆä¸Šä¸‹æ–‡ & è°ƒç”¨LLM

æŠŠç”¨æˆ·é—®é¢˜å’Œæ£€ç´¢åˆ°çš„æ–‡æ¡£æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œä½œä¸º LLM çš„è¾“å…¥ã€‚
------
context = "\n".join(retrieved_docs)
prompt = f"å·²çŸ¥ä¿¡æ¯ï¼š{context}\n\nè¯·å›ç­”ç”¨æˆ·é—®é¢˜ï¼š{query}"

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}]
)

print(response.choices[0].message.content)
------

4. è¾“å‡ºç»“æœ

LLM åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆã€‚

ç­”æ¡ˆæ—¢ç»“åˆäº†å¤§æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›ï¼Œä¹Ÿåˆ©ç”¨äº†å¤–éƒ¨çŸ¥è¯†ã€‚

ğŸ”¹ æ€»ç»“

ä»£ç å®ç° RAG çš„å¤§è‡´æ­¥éª¤æ˜¯ï¼š

å‡†å¤‡æ•°æ® â†’ å»ºç«‹å‘é‡åº“

ç”¨æˆ·è¾“å…¥ â†’ è½¬ embedding

å‘é‡æ£€ç´¢ â†’ æ‰¾ç›¸å…³æ–‡æ¡£

æ‹¼æ¥ä¸Šä¸‹æ–‡ â†’ è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
