RAG 的代码实现流程

1. 数据准备 & 向量化

收集你的文档（PDF、网页、数据库记录等）。

使用 embedding 模型（如 OpenAI Embeddings、Sentence-BERT）把文档切分成片段，并转化为向量。

把这些向量存入一个 向量数据库（如 Pinecone、FAISS、Weaviate）。
------
from openai import OpenAI
import faiss
import numpy as np

client = OpenAI()

# 示例文档
docs = ["宝马发布了最新 recall...", "RAG 是一种增强生成模型的架构..."]

# 获取向量
embeddings = [client.embeddings.create(model="text-embedding-ada-002", input=doc).data[0].embedding for doc in docs]

# 存入向量库 (FAISS)
dim = len(embeddings[0])
index = faiss.IndexFlatL2(dim)
index.add(np.array(embeddings).astype('float32'))
------

2. 用户输入查询

用户提出问题，把问题转化为向量 embedding。

在向量库中检索最相关的文档。

------
query = "宝马 recall 一般涉及哪些更新？"
query_vec = client.embeddings.create(model="text-embedding-ada-002", input=query).data[0].embedding

# 检索前2个最相似文档
D, I = index.search(np.array([query_vec]).astype('float32'), k=2)
retrieved_docs = [docs[i] for i in I[0]]
------


3. 组合上下文 & 调用LLM

把用户问题和检索到的文档拼接在一起，作为 LLM 的输入。
------
context = "\n".join(retrieved_docs)
prompt = f"已知信息：{context}\n\n请回答用户问题：{query}"

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}]
)

print(response.choices[0].message.content)
------

4. 输出结果

LLM 基于检索到的上下文生成答案。

答案既结合了大模型的语言能力，也利用了外部知识。

🔹 总结

代码实现 RAG 的大致步骤是：

准备数据 → 建立向量库

用户输入 → 转 embedding

向量检索 → 找相关文档

拼接上下文 → 调用LLM生成答案

----------------------------------------
Distances（距离） 或 相似度分数

表示查询向量和库中向量之间的“接近程度”。

数值越小（欧式距离 L2）或越大（余弦相似度），说明越相关。

D = 相似度/距离分数

I = 命中的文档索引

确实 docs 里有 3 个元素，但返回的 D 和 I 只有 2 个，是因为我们在调用 index.search() 的时候写了：

D, I = index.search(query_vec, k=2)


这里的 k=2 就决定了：
👉 只返回最相关的 2 个文档，而不是所有文档。
-------------------------------------

假设有 3 篇文档：

docs = [
  "宝马 recall 更新电池管理系统",   # index 0
  "RAG 是检索增强生成",             # index 1
  "宝马发布软件升级"                 # index 2
]


用户问：“宝马 recall 一般更新什么？”

假设相似度计算结果是：

文档 index	文档内容	相似度（余弦分数）
0	宝马 recall 更新电池管理系统	0.95
1	RAG 是检索增强生成	0.10
2	宝马发布软件升级	0.85

如果 k=2，系统只返回最相关的两个：

D = [[0.95, 0.85]]
I = [[0, 2]]


对应的是：

第 0 个文档（最相关）

第 2 个文档（第二相关）

如果改成 k=3

那么会包含全部 3 篇：

D = [[0.95, 0.85, 0.10]]
I = [[0, 2, 1]]


这样你就能看到所有文档的相关性。
