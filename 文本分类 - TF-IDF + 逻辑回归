#、数据准备（示例）
#我们用一个模拟的数据集（可以替换为自己的语料）。

import pandas as pd

# 构造一个简单示例数据集
data = {
    "text": [
        "这部电影太棒了，我非常喜欢！",
        "剧情无聊透顶，浪费时间。",
        "演员的表演很到位，让人感动。",
        "音效和画面都很差。",
        "整体来说是一部很好的影片。",
        "糟糕的剧本，演技一般。"
    ],
    "label": [1, 0, 1, 0, 1, 0]  # 1=正面，0=负面
}
df = pd.DataFrame(data)
print(df)

             text  label
0  这部电影太棒了，我非常喜欢！      1
1    剧情无聊透顶，浪费时间。      0
2  演员的表演很到位，让人感动。      1
3       音效和画面都很差。      0
4   整体来说是一部很好的影片。      1
5     糟糕的剧本，演技一般。      0

--------------------------------------------------------------
#Step 1 文本预处理

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

import jieba
def tokenizer(text):
    return jieba.lcut(text)

vectorizer = TfidfVectorizer(tokenizer=tokenizer)

# 中文文本可直接使用 TF-IDF，scikit-learn 默认按空格切词
# 如果要更好效果，可以用 jieba 做分词
# 用训练集来拟合词表
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf  = vectorizer.transform(X_test)

-------------------------------------------------------------
#Step 2 模型训练
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer

clf = LogisticRegression(max_iter=500)
clf.fit(X_train_tfidf, y_train)

y_pred = clf.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))


              precision    recall  f1-score   support

           0       0.50      1.00      0.67         1
           1       0.00      0.00      0.00         1

    accuracy                           0.50         2
   macro avg       0.25      0.50      0.33         2
weighted avg       0.25      0.50      0.33         2

-----------------------------------------------------------

#Step 3 推理
new_texts = ["这部电影真的很好看！", "一点都不值得看。"]
new_tfidf = vectorizer.transform(new_texts)   # ✅ 注意这里用 transform()
preds = clf.predict(new_tfidf)
print(preds)  # [1 0]


